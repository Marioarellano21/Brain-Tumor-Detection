# %% Imports
# Arreglo de compatibilidad Python 3.10 - DEBE IR PRIMERO
import sys
import collections.abc
collections.Iterable = collections.abc.Iterable
collections.Mapping = collections.abc.Mapping
collections.MutableMapping = collections.abc.MutableMapping

# Arreglo para NumPy 2.0+ con Keras 2.2.4
import numpy as np
if not hasattr(np, 'Inf'):
    np.Inf = np.inf
print(f"NumPy version: {np.__version__} (arreglo np.Inf aplicado)")

# Configurar PlaidML ANTES de cualquier import de Keras
import plaidml.keras
plaidml.keras.install_backend()

# Imports b√°sicos
import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
from datetime import datetime

# Librer√≠as de Scikit-learn para preprocesamiento y m√©tricas
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc

# Imbalanced-learn para manejar desbalance de clases
from imblearn.over_sampling import RandomOverSampler

# CAMBIO PRINCIPAL: Usar keras en lugar de tensorflow.keras
import keras
from keras import layers, Model, callbacks
from keras.optimizers import Adam
from keras.preprocessing.image import ImageDataGenerator
from keras.applications import ResNet50
from keras.applications.resnet50 import preprocess_input
# AUC no est√° disponible en Keras 2.2.4, la calcularemos manualmente

from tqdm import tqdm

# Configuraci√≥n para la visualizaci√≥n
sns.set_style("whitegrid")

print("üöÄ PlaidML configurado para GPU AMD gfx90c")
print(f"‚úÖ Keras version: {keras.__version__}")
print(f"‚úÖ Backend: {keras.backend.backend()}")

# %% Carga de datos
base_path = "../images"  # Directorio ra√≠z donde se encuentran las carpetas de categor√≠as
categories = ["Healthy", "Tumor"] # Nombres de las subcarpetas y nuestras clases

image_paths = []  # Lista para almacenar las rutas a cada imagen
labels = []       # Lista para almacenar la etiqueta de cada imagen

valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff')  # Opcional, para filtrar im√°genes

# Iterar sobre cada categor√≠a definida
for category in categories:
    category_path = os.path.join(base_path, category)
    if os.path.isdir(category_path):
        for image_name in tqdm(os.listdir(category_path), desc=f"Cargando {category}"):
            if image_name.lower().endswith(valid_extensions):  # Filtra solo im√°genes
                image_path = os.path.join(category_path, image_name)
                image_paths.append(image_path)
                labels.append(category)
    else:
        print(f"Advertencia: El directorio para la categor√≠a '{category}' no fue encontrado en '{category_path}'")

# Crear un DataFrame de Pandas para almacenar las rutas de las im√°genes y sus etiquetas
df = pd.DataFrame({"image_path": image_paths, "label": labels})

# Mostrar las primeras filas del DataFrame y la distribuci√≥n de clases
print("DataFrame inicial con rutas de im√°genes y etiquetas:")
print(df.head())
print("\nDistribuci√≥n de clases inicial:")
print(df['label'].value_counts())

# %% Preprocesamiento
# Codificaci√≥n de etiquetas
label_encoder = LabelEncoder()
# Se crea una nueva columna 'category_encoded' con las etiquetas num√©ricas (ej. 0 para Healthy, 1 para Tumor)
df['category_encoded'] = label_encoder.fit_transform(df['label'])

print("DataFrame despu√©s de la codificaci√≥n de etiquetas:")
print(df.head())
print(f"Clases codificadas: {label_encoder.classes_} -> {label_encoder.transform(label_encoder.classes_)}")

# Primero, dividir en entrenamiento (80%) y un conjunto temporal (20% para validaci√≥n + prueba)
X_train_original, X_temp, y_train_original, y_temp = train_test_split(
    df[['image_path']],  # Caracter√≠sticas (rutas de imagen como DataFrame)
    df['category_encoded'], # Etiquetas num√©ricas
    train_size=0.8,         # 80% para entrenamiento
    shuffle=True,           # Mezclar los datos antes de dividir
    random_state=42,        # Para reproducibilidad
    stratify=df['category_encoded'] # Asegurar proporciones de clase similares en la divisi√≥n
)

# Luego, dividir el conjunto temporal en validaci√≥n (50% de temp -> 10% del total)
X_valid, X_test, y_valid, y_test = train_test_split(
    X_temp,                 # DataFrame con rutas de imagen del conjunto temporal
    y_temp,                 # Etiquetas del conjunto temporal
    test_size=0.5,          # 50% de X_temp para el conjunto de prueba (el resto para validaci√≥n)
    shuffle=True,
    random_state=42,
    stratify=y_temp         # Estratificar sobre las etiquetas del conjunto temporal
)

ros = RandomOverSampler(random_state=42)
X_train_resampled, y_train_resampled = ros.fit_resample(X_train_original, y_train_original)

# train_df utilizar√° los datos de entrenamiento sobremuestreados.
train_df = pd.DataFrame(X_train_resampled, columns=['image_path'])
train_df['category_encoded'] = y_train_resampled.astype(str)

# valid_df y test_df utilizan los datos originales de validaci√≥n y prueba, sin sobremuestreo.
valid_df = pd.DataFrame(X_valid, columns=['image_path'])
valid_df['category_encoded'] = y_valid.astype(str)

test_df = pd.DataFrame(X_test, columns=['image_path'])
test_df['category_encoded'] = y_test.astype(str)

# %% Generadores de datos para ResNet
batch_size = 32  # CONFIGURACI√ìN REAL - Aprovechando GPU completa
img_size = (224, 224)  # ResNet requiere 224x224

print(f"üéØ CONFIGURACI√ìN PARA ENTRENAMIENTO FASE 1 √öNICAMENTE:")
print(f"   - Batch size: {batch_size}")
print(f"   - Image size: {img_size}")
print(f"   - √âpocas: 20 (solo Fase 1)")
print(f"   - GPU Memory: 7GB disponibles")
print(f"   - Learning rate: 1e-3 (sin fine-tuning)")
print(f"   - Estrategia: Mantener ResNet50 congelado para estabilidad")

# Data augmentation para entrenamiento
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,  # Preprocesamiento espec√≠fico de ResNet
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Solo preprocesamiento para validaci√≥n y prueba
test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)

# Generador para el conjunto de entrenamiento
train_gen = train_datagen.flow_from_dataframe(
    train_df,                   # DataFrame con datos de entrenamiento (sobremuestreados)
    x_col='image_path',         # Columna con las rutas de las im√°genes
    y_col='category_encoded',   # Columna con las etiquetas codificadas (como string)
    target_size=img_size,       # Tama√±o al que se redimensionar√°n las im√°genes
    class_mode='binary',        # Para clasificaci√≥n binaria
    color_mode='rgb',           # Cargar im√°genes en color
    shuffle=True,               # Mezclar los datos de entrenamiento en cada √©poca
    batch_size=batch_size
)

# Generador para el conjunto de validaci√≥n
valid_gen = test_datagen.flow_from_dataframe(
    valid_df,                   # DataFrame con datos de validaci√≥n (originales)
    x_col='image_path',
    y_col='category_encoded',
    target_size=img_size,
    class_mode='binary',
    color_mode='rgb',
    shuffle=False,              # ‚úÖ CORREGIDO: No mezclar validaci√≥n
    batch_size=batch_size
)

# Generador para el conjunto de prueba
test_gen = test_datagen.flow_from_dataframe(
    test_df,                    # DataFrame con datos de prueba (originales)
    x_col='image_path',
    y_col='category_encoded',
    target_size=img_size,
    class_mode='binary',
    color_mode='rgb',
    shuffle=False,              # IMPORTANTE: No mezclar el conjunto de prueba
    batch_size=batch_size
)

print("\nGeneradores creados:")
print(f"Entrenamiento: {train_gen.samples} im√°genes")
print(f"Validaci√≥n: {valid_gen.samples} im√°genes")
print(f"Prueba: {test_gen.samples} im√°genes")

# %% Construcci√≥n del modelo ResNet50
def build_resnet_model(input_shape=(224, 224, 3)):
    # Cargar ResNet50 preentrenada (sin las capas superiores de clasificaci√≥n de ImageNet)
    base_model = ResNet50(
        include_top=False,      # No incluir la capa densa final de ResNet50
        weights='imagenet',     # Usar pesos pre-entrenados en ImageNet
        input_shape=input_shape # Definir la forma de entrada de las im√°genes
    )

    # Congelar las capas del modelo base PERMANENTEMENTE
    # Sus pesos NO se actualizar√°n nunca - estrategia estable
    base_model.trainable = False

    # Construir el modelo completo a√±adiendo nuestras propias capas encima de ResNet50
    inputs = layers.Input(shape=input_shape) # Capa de entrada
    # Pasar las entradas a trav√©s del modelo base.
    x = base_model(inputs)  # Quitar training=False para Keras 2.2.4
    # Reducir la dimensionalidad espacial a un vector por cada mapa de caracter√≠sticas.
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dropout(0.5)(x)  # Capa de Dropout para regularizaci√≥n
    # Capa densa final para la clasificaci√≥n binaria, con activaci√≥n sigmoide.
    # Se a√±ade regularizaci√≥n L2 al kernel para prevenir el sobreajuste.
    outputs = layers.Dense(1, activation='sigmoid',
                          kernel_regularizer=keras.regularizers.l2(0.01))(x)

    # Crear el modelo final especificando las entradas y salidas.
    model = Model(inputs, outputs)
    return model

# Instanciar el modelo
model = build_resnet_model()

# Compilaci√≥n del modelo
model.compile(
    optimizer=Adam(lr=1e-3),  # En Keras 2.2.4 es 'lr' no 'learning_rate'
    loss='binary_crossentropy',         # Funci√≥n de p√©rdida para clasificaci√≥n binaria
    metrics=['accuracy']  # AUC se calcular√° manualmente
)

# Crear carpeta results para guardar todo
results_dir = "../results"
import os
os.makedirs(results_dir, exist_ok=True)
print(f"üìÅ Carpeta de resultados: {results_dir}")

# Callbacks para el entrenamiento
callbacks_list = [
    callbacks.EarlyStopping(
        monitor='val_loss',       # Cambiar a val_loss ya que no tenemos val_auc
        patience=7,               # M√°s paciencia para 20 √©pocas
        mode='min',               # Minimizar la p√©rdida
        restore_best_weights=True,# Restaura los pesos del modelo de la mejor √©poca al finalizar
        verbose=1                 # Muestra mensajes cuando el callback se activa
    ),
    callbacks.ReduceLROnPlateau(
        monitor='val_loss',       # M√©trica a monitorear (p√©rdida en el conjunto de validaci√≥n)
        factor=0.2,               # Factor por el cual se reduce la tasa de aprendizaje
        patience=4,               # N√∫mero de √©pocas a esperar sin mejora antes de reducir LR
        verbose=1,
        min_lr=1e-7
    ),
    callbacks.ModelCheckpoint(
        os.path.join(results_dir, 'best_resnet_phase1_only.h5'), # Guardar en results
        monitor='val_loss',       # Monitorear p√©rdida de validaci√≥n
        save_best_only=True,      # Guarda solo el modelo si la m√©trica monitoreada ha mejorado
        mode='min',               # El objetivo es minimizar val_loss
        verbose=1
    )
]

# SOLO FASE 1: Entrenar √∫nicamente las capas nuevas
print("\n" + "="*70)
print("üöÄ ENTRENAMIENTO FASE 1 √öNICAMENTE - SIN FINE-TUNING")
print("="*70)

training_start_time = datetime.now()
print(f"‚è∞ Inicio del entrenamiento: {training_start_time.strftime('%Y-%m-%d %H:%M:%S')}")
print(f"üéØ Estrategia: Solo entrenar capas nuevas (ResNet50 congelado)")
print(f"üí° Ventaja: Modelo estable, sin riesgo de destruir pesos pre-entrenados")
print(f"üìä Dataset: {train_gen.samples} train, {valid_gen.samples} val, {test_gen.samples} test")

print(f"\nüìä ENTRENAMIENTO: Capas nuevas √∫nicamente (20 √©pocas)")
training_start = datetime.now()
print(f"‚è∞ Inicio entrenamiento: {training_start.strftime('%H:%M:%S')}")
print(f"üîß Learning rate: 1e-3 (estable)")

# 20 √âPOCAS de entrenamiento estable
epochs = 20
history = model.fit_generator(  # En Keras 2.2.4 es fit_generator
    train_gen,
    validation_data=valid_gen,
    epochs=epochs,
    callbacks=callbacks_list, # Utilizar la lista de callbacks definida
    verbose=1                 # Mostrar barra de progreso e informaci√≥n por √©poca
)

training_end = datetime.now()
training_duration = training_end - training_start
print(f"\n‚úÖ ENTRENAMIENTO COMPLETADO!")
print(f"‚è∞ Fin entrenamiento: {training_end.strftime('%H:%M:%S')}")
print(f"‚è±Ô∏è Duraci√≥n total: {training_duration}")
print(f"üìä Mejor val_acc: {max(history.history['val_acc']):.4f}")
print(f"üìä Mejor val_loss: {min(history.history['val_loss']):.4f}")
print(f"üìä √âpocas completadas: {len(history.history['val_acc'])}")

# Calcular AUC de validaci√≥n
print(f"\nüìà Calculando AUC de validaci√≥n...")
try:
    valid_gen.reset()
    y_pred_probs_val = model.predict_generator(valid_gen, verbose=0)
    y_true_val = valid_gen.classes
    from sklearn.metrics import roc_auc_score
    auc_val = roc_auc_score(y_true_val, y_pred_probs_val)
    print(f"üéØ AUC Validaci√≥n: {auc_val:.4f}")
except Exception as e:
    print(f"‚ö†Ô∏è No se pudo calcular AUC: {e}")

# Resumen final del entrenamiento
total_duration = training_end - training_start_time

print(f"\n" + "="*70)
print("üéâ ENTRENAMIENTO FASE 1 FINALIZADO")
print("="*70)
print(f"‚è∞ Inicio: {training_start_time.strftime('%Y-%m-%d %H:%M:%S')}")
print(f"‚è∞ Fin: {training_end.strftime('%Y-%m-%d %H:%M:%S')}")
print(f"‚è±Ô∏è Duraci√≥n total: {total_duration}")
print(f"üìä Mejor val_acc: {max(history.history['val_acc']):.4f}")
print(f"üìä Mejor val_loss: {min(history.history['val_loss']):.4f}")
print(f"üéØ AUC Validaci√≥n: {auc_val:.4f}")
print(f"üí° Modelo estable sin fine-tuning destructivo")

# Cargar el mejor modelo antes de evaluar
print(f"\nüîÑ Cargando mejor modelo guardado...")
best_model_path = os.path.join(results_dir, 'best_resnet_phase1_only.h5')
try:
    model.load_weights(best_model_path)
    print(f"‚úÖ Modelo √≥ptimo restaurado desde {best_model_path}")
except Exception as e:
    print(f"‚ö†Ô∏è Error cargando pesos: {e}")
    print(f"‚úÖ Usando modelo actual (callbacks ya restauraron el mejor)")

# Guardar modelo en formatos compatibles para Streamlit
print(f"\nüíæ Guardando modelo para uso en Streamlit...")

# M√©todo 1: Intentar guardar modelo completo
streamlit_model_path = os.path.join(results_dir, 'brain_tumor_phase1_streamlit.h5')
try:
    model.save(streamlit_model_path)
    print(f"‚úÖ Modelo completo guardado: {streamlit_model_path}")
    
    # Test de carga inmediata
    test_model = keras.models.load_model(streamlit_model_path)
    print(f"‚úÖ Test de carga exitoso - modelo funcional")
    del test_model
    
except Exception as e:
    print(f"‚ö†Ô∏è Error con modelo completo: {e}")
    
    # M√©todo 2: Guardar solo pesos (m√°s compatible)
    try:
        print(f"üì¶ Guardando en formato alternativo...")
        
        # Guardar pesos sin metadata problem√°tica
        weights_path = os.path.join(results_dir, 'brain_tumor_phase1_weights.h5')
        model.save_weights(weights_path, overwrite=True)
        
        # Guardar arquitectura
        import json
        model_config = model.to_json()
        arch_path = os.path.join(results_dir, 'brain_tumor_phase1_architecture.json')
        with open(arch_path, 'w') as f:
            json.dump(json.loads(model_config), f, indent=2)
        
        print(f"‚úÖ Pesos guardados: {weights_path}")
        print(f"‚úÖ Arquitectura guardada: {arch_path}")
        
        # Test de reconstrucci√≥n
        test_model = keras.models.model_from_json(model_config)
        test_model.load_weights(weights_path)
        print(f"‚úÖ Test de reconstrucci√≥n exitoso")
        del test_model
        
    except Exception as e2:
        print(f"‚ùå Error guardando alternativo: {e2}")

# Guardar informaci√≥n esencial para Streamlit
try:
    import pickle
    
    # Guardar label encoder
    encoder_path = os.path.join(results_dir, 'label_encoder_phase1.pkl')
    with open(encoder_path, 'wb') as f:
        pickle.dump(label_encoder, f)
    
    # Guardar configuraci√≥n del modelo
    model_info = {
        'input_shape': (224, 224, 3),
        'classes': list(label_encoder.classes_),
        'preprocessing': 'resnet50_preprocess_input',
        'threshold': 0.5,
        'model_type': 'ResNet50_phase1_only',
        'training_epochs': len(history.history['val_acc']),
        'best_val_acc': max(history.history['val_acc']),
        'best_val_loss': min(history.history['val_loss']),
        'auc_validation': auc_val
    }
    
    config_path = os.path.join(results_dir, 'model_config_phase1.pkl')
    with open(config_path, 'wb') as f:
        pickle.dump(model_info, f)
    
    print(f"‚úÖ Label encoder guardado: {encoder_path}")
    print(f"‚úÖ Configuraci√≥n guardada: {config_path}")
    
except Exception as e:
    print(f"‚ö†Ô∏è Error guardando configuraci√≥n: {e}")

print("="*70)

# %% Evaluaci√≥n del modelo
def evaluate_model(model, test_gen):
    print(f"\n{'='*70}")
    print("üìä EVALUACI√ìN FINAL DEL MODELO EN CONJUNTO DE PRUEBA")
    print("="*70)
    
    eval_start = datetime.now()
    print(f"‚è∞ Inicio evaluaci√≥n: {eval_start.strftime('%H:%M:%S')}")
    
    # Reiniciar el generador de prueba para asegurar que empieza desde el principio
    test_gen.reset()
    # Evaluar el modelo en el conjunto de prueba
    loss, accuracy = model.evaluate_generator(test_gen, verbose=1)  # Keras 2.2.4 usa evaluate_generator

    print(f"\nüìà RESULTADOS EN CONJUNTO DE PRUEBA:")
    print(f"üìä P√©rdida (Loss): {loss:.4f}")
    print(f"üìä Exactitud (Accuracy): {accuracy:.4f}")

    # Obtener las probabilidades predichas por el modelo para el conjunto de prueba
    test_gen.reset()
    y_pred_probs = model.predict_generator(test_gen, verbose=0)  # En Keras 2.2.4 es predict_generator
    # Convertir las probabilidades a predicciones de clase (0 o 1) usando un umbral de 0.5
    y_pred = (y_pred_probs > 0.5).astype(int).flatten()
    # Obtener las etiquetas verdaderas del generador de prueba
    y_true = test_gen.classes

    # Calcular AUC manualmente
    from sklearn.metrics import roc_auc_score
    auc_score = roc_auc_score(y_true, y_pred_probs)
    
    eval_end = datetime.now()
    eval_duration = eval_end - eval_start
    print(f"üìä AUC: {auc_score:.4f}")
    print(f"‚è∞ Fin evaluaci√≥n: {eval_end.strftime('%H:%M:%S')}")
    print(f"‚è±Ô∏è Duraci√≥n evaluaci√≥n: {eval_duration}")

    # Obtener los nombres originales de las clases usando el label_encoder ajustado previamente
    class_names = list(label_encoder.inverse_transform([0, 1]))

    # --- Matriz de Confusi√≥n ---
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names)
    plt.title('Matriz de Confusi√≥n - ResNet50 Fase 1 √önicamente')
    plt.ylabel('Etiqueta Verdadera')
    plt.xlabel('Etiqueta Predicha')
    
    # Guardar matriz de confusi√≥n
    confusion_matrix_path = os.path.join(results_dir, 'confusion_matrix.png')
    plt.savefig(confusion_matrix_path, dpi=300, bbox_inches='tight')
    print(f"üìä Matriz de confusi√≥n guardada: {confusion_matrix_path}")
    plt.show()

    # --- Reporte de Clasificaci√≥n ---
    print("\nüìã REPORTE DE CLASIFICACI√ìN:")
    report = classification_report(y_true, y_pred, target_names=class_names)
    print(report)
    
    # Guardar reporte de clasificaci√≥n
    report_path = os.path.join(results_dir, 'classification_report.txt')
    with open(report_path, 'w') as f:
        f.write("REPORTE DE CLASIFICACI√ìN - ResNet50 Fase 1\n")
        f.write("="*50 + "\n\n")
        f.write(report)
        f.write(f"\n\nAUC Score: {auc_score:.4f}\n")
        f.write(f"Loss: {loss:.4f}\n")
        f.write(f"Accuracy: {accuracy:.4f}\n")
    print(f"üìã Reporte guardado: {report_path}")

    # --- Curva ROC ---
    # Calcular la tasa de falsos positivos (fpr) y la tasa de verdaderos positivos (tpr)
    fpr, tpr, _ = roc_curve(y_true, y_pred_probs) # Usar y_pred_probs para la curva ROC
    # Calcular el √Årea Bajo la Curva ROC
    roc_auc = auc(fpr, tpr)

    plt.figure(figsize=(10, 8))
    plt.plot(fpr, tpr, color='darkorange', lw=3,
             label=f'Curva ROC (AUC = {roc_auc:.3f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='L√≠nea base') # L√≠nea de no discriminaci√≥n
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('Tasa de Falsos Positivos (FPR)')
    plt.ylabel('Tasa de Verdaderos Positivos (TPR)')
    plt.title('Curva ROC - ResNet50 Fase 1 √önicamente')
    plt.legend(loc="lower right")
    plt.grid(True, alpha=0.3)
    
    # Guardar curva ROC
    roc_curve_path = os.path.join(results_dir, 'roc_curve.png')
    plt.savefig(roc_curve_path, dpi=300, bbox_inches='tight')
    print(f"üìà Curva ROC guardada: {roc_curve_path}")
    plt.show()
    
    print(f"{'='*70}")
    return auc_score

# Llamar a la funci√≥n de evaluaci√≥n con el modelo entrenado y el generador de prueba
final_auc = evaluate_model(model, test_gen)

print(f"\nüèÜ RESUMEN FINAL DEL PROYECTO:")
print(f"üéØ AUC Final: {final_auc:.4f}")
print(f"üìä Accuracy Final: {max(history.history['val_acc']):.4f}")
print(f"‚è±Ô∏è Tiempo total entrenamiento: {total_duration}")
print(f"üöÄ Entrenamiento completado exitosamente en GPU AMD gfx90c!")
print(f"üíæ Modelo guardado en: best_resnet_phase1_only.h5")
print(f"üí° Estrategia estable: Solo Fase 1, sin fine-tuning destructivo")

# %% Visualizaci√≥n del historial de entrenamiento
def plot_training_history(training_hist):
    # Extraer m√©tricas
    acc = training_hist.history['acc']
    val_acc = training_hist.history['val_acc']
    loss = training_hist.history['loss']
    val_loss = training_hist.history['val_loss']

    plt.figure(figsize=(15, 6))

    # Subgr√°fico para la Exactitud
    plt.subplot(1, 2, 1)
    epochs = range(1, len(acc) + 1)
    plt.plot(epochs, acc, 'bo-', label='Exactitud de Entrenamiento', markersize=4)
    plt.plot(epochs, val_acc, 'ro-', label='Exactitud de Validaci√≥n', markersize=4)
    plt.title('Exactitud durante Entrenamiento - ResNet50 Fase 1', fontsize=14)
    plt.xlabel('√âpoca')
    plt.ylabel('Exactitud')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # Subgr√°fico para la P√©rdida
    plt.subplot(1, 2, 2)
    plt.plot(epochs, loss, 'bo-', label='P√©rdida de Entrenamiento', markersize=4)
    plt.plot(epochs, val_loss, 'ro-', label='P√©rdida de Validaci√≥n', markersize=4)
    plt.title('P√©rdida durante Entrenamiento - ResNet50 Fase 1', fontsize=14)
    plt.xlabel('√âpoca')
    plt.ylabel('P√©rdida')
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.tight_layout() # Ajustar el layout para evitar superposiciones
    
    # Guardar gr√°fica de entrenamiento
    training_history_path = os.path.join(results_dir, 'training_history.png')
    plt.savefig(training_history_path, dpi=300, bbox_inches='tight')
    print(f"üìà Historial de entrenamiento guardado: {training_history_path}")
    plt.show()

# Llamar a la funci√≥n para graficar el historial
print(f"\nüìà Generando gr√°ficas del historial de entrenamiento...")
plot_training_history(history)

# Guardar historial de entrenamiento en formato pickle
history_data = {
    'accuracy': history.history['acc'],
    'val_accuracy': history.history['val_acc'], 
    'loss': history.history['loss'],
    'val_loss': history.history['val_loss'],
    'epochs': len(history.history['acc']),
    'training_time': total_duration
}

history_pickle_path = os.path.join(results_dir, 'training_history.pkl')
with open(history_pickle_path, 'wb') as f:
    pickle.dump(history_data, f)
print(f"üíæ Historial guardado: {history_pickle_path}")

print(f"\nüéâ ¬°PROYECTO COMPLETADO EXITOSAMENTE!")
print(f"üìä Resumen de rendimiento de GPU AMD gfx90c:")
print(f"   - Total √©pocas: {len(history.history['val_acc'])}")
print(f"   - Mejor accuracy: {max(history.history['val_acc']):.4f}")
print(f"   - AUC final: {final_auc:.4f}")
print(f"   - Tiempo promedio/√©poca: {total_duration.total_seconds()/(len(history.history['val_acc'])*60):.1f} min")
print(f"   - Estrategia: Fase 1 √∫nicamente (estable)")
print(f"üöÄ GPU AMD funcionando perfectamente para Deep Learning!")
print(f"üí° Modelo listo para producci√≥n sin riesgo de fine-tuning destructivo")

print(f"\nüìÅ ARCHIVOS GUARDADOS EN {results_dir}:")
print(f"   ü§ñ brain_tumor_phase1_streamlit.h5 - Modelo para Streamlit")
print(f"   üè∑Ô∏è label_encoder_phase1.pkl - Codificador de etiquetas")
print(f"   ‚öôÔ∏è model_config_phase1.pkl - Configuraci√≥n del modelo")
print(f"   üìä confusion_matrix.png - Matriz de confusi√≥n")
print(f"   üìà roc_curve.png - Curva ROC")
print(f"   üìâ training_history.png - Historial de entrenamiento")
print(f"   üìã classification_report.txt - Reporte detallado")
print(f"   üìÑ training_summary.txt - Resumen final")
print(f"   üíæ training_history.pkl - Historial en formato pickle")

# Script de diagn√≥stico para el problema de AUC
def diagnose_auc_problem(model, valid_gen, test_gen, label_encoder):
    """
    Diagnostica las diferencias en el c√°lculo de AUC
    """
    print("\nüîç DIAGN√ìSTICO DEL PROBLEMA DE AUC")
    print("="*50)
    
    # 1. AUC en conjunto de validaci√≥n
    print("\nüìä CONJUNTO DE VALIDACI√ìN:")
    valid_gen.reset()
    y_pred_probs_val = model.predict_generator(valid_gen, verbose=0)
    y_true_val = valid_gen.classes
    
    print(f"   - Samples: {len(y_true_val)}")
    print(f"   - Distribuci√≥n real: {np.bincount(y_true_val)}")
    print(f"   - Predicciones shape: {y_pred_probs_val.shape}")
    print(f"   - Predicciones min/max: [{y_pred_probs_val.min():.3f}, {y_pred_probs_val.max():.3f}]")
    
    # Calcular AUC validaci√≥n
    try:
        auc_val = roc_auc_score(y_true_val, y_pred_probs_val)
        print(f"   üéØ AUC Validaci√≥n: {auc_val:.4f}")
    except Exception as e:
        print(f"   ‚ùå Error calculando AUC validaci√≥n: {e}")
    
    # 2. AUC en conjunto de prueba
    print("\nüìä CONJUNTO DE PRUEBA:")
    test_gen.reset()
    y_pred_probs_test = model.predict_generator(test_gen, verbose=0)
    y_true_test = test_gen.classes
    
    print(f"   - Samples: {len(y_true_test)}")
    print(f"   - Distribuci√≥n real: {np.bincount(y_true_test)}")
    print(f"   - Predicciones shape: {y_pred_probs_test.shape}")
    print(f"   - Predicciones min/max: [{y_pred_probs_test.min():.3f}, {y_pred_probs_test.max():.3f}]")
    
    # Calcular AUC prueba
    try:
        auc_test = roc_auc_score(y_true_test, y_pred_probs_test)
        print(f"   üéØ AUC Prueba: {auc_test:.4f}")
    except Exception as e:
        print(f"   ‚ùå Error calculando AUC prueba: {e}")
    
    # 3. Verificar curva ROC manualmente
    print("\nüìà CURVA ROC MANUAL (conjunto de prueba):")
    try:
        fpr, tpr, thresholds = roc_curve(y_true_test, y_pred_probs_test)
        roc_auc_manual = auc(fpr, tpr)
        print(f"   üéØ AUC de curva ROC: {roc_auc_manual:.4f}")
        print(f"   - Puntos FPR: {len(fpr)}")
        print(f"   - Puntos TPR: {len(tpr)}")
    except Exception as e:
        print(f"   ‚ùå Error con curva ROC: {e}")
    
    # 4. Verificar distribuci√≥n de predicciones
    print("\nüìä DISTRIBUCI√ìN DE PREDICCIONES:")
    
    # Para validaci√≥n
    y_pred_binary_val = (y_pred_probs_val > 0.5).astype(int).flatten()
    print(f"   Validaci√≥n - Predicciones binarias: {np.bincount(y_pred_binary_val)}")
    
    # Para prueba
    y_pred_binary_test = (y_pred_probs_test > 0.5).astype(int).flatten()
    print(f"   Prueba - Predicciones binarias: {np.bincount(y_pred_binary_test)}")
    
    # 5. Verificar mapeo de clases
    print("\nüè∑Ô∏è MAPEO DE CLASES:")
    print(f"   Label encoder classes: {label_encoder.classes_}")
    print(f"   Transformaci√≥n: {label_encoder.transform(label_encoder.classes_)}")
    
    # 6. Matriz de confusi√≥n detallada
    print("\nüìã MATRICES DE CONFUSI√ìN:")
    
    # Validaci√≥n
    cm_val = confusion_matrix(y_true_val, y_pred_binary_val)
    print(f"   Validaci√≥n:")
    print(f"   {cm_val}")
    
    # Prueba
    cm_test = confusion_matrix(y_true_test, y_pred_binary_test)
    print(f"   Prueba:")
    print(f"   {cm_test}")
    
    # 7. An√°lisis estad√≠stico
    print("\nüìà AN√ÅLISIS ESTAD√çSTICO:")
    
    # Accuracy comparativa
    acc_val = np.mean(y_true_val == y_pred_binary_val)
    acc_test = np.mean(y_true_test == y_pred_binary_test)
    print(f"   Accuracy validaci√≥n: {acc_val:.4f}")
    print(f"   Accuracy prueba: {acc_test:.4f}")
    
    print(f"\nüéØ CONCLUSI√ìN:")
    print(f"   AUC Validaci√≥n: {auc_val:.4f}")
    print(f"   AUC Prueba: {auc_test:.4f}")
    print(f"   Diferencia: {abs(auc_val - auc_test):.4f}")
    
    if abs(auc_val - auc_test) > 0.1:
        print(f"   ‚ö†Ô∏è GRAN DIFERENCIA - Posible overfitting o error en datos")
    elif auc_val < 0.6 and auc_test > 0.9:
        print(f"   ü§î PATR√ìN EXTRA√ëO - Revisar generadores y mapeo de clases")
    else:
        print(f"   ‚úÖ Diferencia normal entre conjuntos")
    
    return auc_val, auc_test, roc_auc_manual

# Ejecutar diagn√≥stico
print("\n" + "="*70)
auc_val_diag, auc_test_diag, auc_manual_diag = diagnose_auc_problem(model, valid_gen, test_gen, label_encoder)
print("="*70)